\relax 
\providecommand\hyper@newdestlabel[2]{}
\bibstyle{biblatex}
\bibdata{dissertation-blx,references}
\citation{biblatex-control}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lof}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lot}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{Abstract}{i}{Doc-Start}}
\newlabel{sec:abstractlabel}{{}{i}{}{Doc-Start}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{Table of Contents}{ii}{Doc-Start}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{List of Algorithms}{iii}{chapter*.1}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{List of Tables}{iv}{chapter*.2}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{List of Figures}{vi}{chapter*.3}}
\citation{Baxter1997}
\citation{Caruana1997}
\citation{thrun1996learning}
\citation{Zhang20141819}
\citation{Borchani2015}
\citation{Jeong2009}
\citation{Lui2010}
\citation{Caruana1997}
\citation{Evgeniou2005}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {1} Introduction }{9}{chapter.1}}
\newlabel{CHAP:CHAPINTRO}{{1}{9}{Introduction}{chapter.1}{}}
\citation{Borchani2015}
\citation{Baxter1997}
\citation{Caruana1997}
\citation{BenDavic2003}
\citation{evgeniou2004regularized}
\citation{Herman2008}
\citation{Yi2016}
\citation{Dietterich1997}
\citation{Dietterich1997}
\citation{Foulds2010}
\citation{Ray2005}
\citation{Maron1998}
\citation{Carbonneau2016}
\citation{Cortes1995}
\citation{Platt1998}
\newlabel{sec:introcontribute}{{1.1}{12}{Contributions of the Proposal \label {sec:introcontribute} }{section.1.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1.1}Contributions of the Proposal  }{12}{section.1.1}}
\citation{Spyromitros2014}
\citation{boser1992training}
\citation{Cortes1995}
\citation{Kecman2001}
\citation{Schoelkopf2002}
\citation{Shalev2014}
\citation{Shalev2014}
\citation{vapnik2015uniform}
\citation{vapnik2015uniform}
\citation{Aizerman67theoretical}
\citation{boser1992training}
\citation{Cortes1995}
\citation{vapnik2013nature}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {2} Background}{15}{chapter.2}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.1}Support Vector Machine Classification}{15}{section.2.1}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces A 2-dimensional example of different possible separating hyperplanes that correctly classify all the toy data points.}}{16}{figure.2.1}}
\newlabel{fig:possiblesephyp}{{2.1}{16}{A 2-dimensional example of different possible separating hyperplanes that correctly classify all the toy data points}{figure.2.1}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces An illustration of the soft margin SVM solution on an example $2$-dimensional non-linearly separable dataset.}}{16}{figure.2.2}}
\newlabel{fig:nonlinsepdata}{{2.2}{16}{An illustration of the soft margin SVM solution on an example $2$-dimensional non-linearly separable dataset}{figure.2.2}{}}
\newlabel{eq:classificationfunction}{{2.1}{16}{Support Vector Machine Classification}{equation.2.1}{}}
\newlabel{eqn:softsvmconstraint}{{2.2}{16}{Support Vector Machine Classification}{equation.2.2}{}}
\citation{Aizerman67theoretical}
\newlabel{eq:softsvm}{{2.3}{17}{Support Vector Machine Classification}{equation.2.3}{}}
\newlabel{eqn:reghingeloss}{{2.5}{17}{Support Vector Machine Classification}{equation.2.5}{}}
\newlabel{eq:kerneltrick}{{2.6}{17}{Support Vector Machine Classification}{equation.2.6}{}}
\citation{Drucker1997}
\citation{vapnik1997support}
\citation{Kecman2001}
\newlabel{eq:output}{{2.7}{18}{Support Vector Machine Classification}{equation.2.7}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.2}Support Vector Regression}{18}{section.2.2}}
\newlabel{eq:epsloss}{{2.8}{18}{Support Vector Regression}{equation.2.8}{}}
\citation{Schoelkopf2002}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Vapnik's $\epsilon $-insensitivity loss function.}}{19}{figure.2.3}}
\newlabel{fig:epsloss}{{2.3}{19}{Vapnik's $\epsilon $-insensitivity loss function}{figure.2.3}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Support vector regression example solution.}}{19}{figure.2.4}}
\newlabel{fig:regressionsvm}{{2.4}{19}{Support vector regression example solution}{figure.2.4}{}}
\newlabel{eq:regsvmemp}{{2.9}{19}{Support Vector Regression}{equation.2.9}{}}
\newlabel{eq:softsvropt}{{2.10}{19}{Support Vector Regression}{equation.2.10}{}}
\newlabel{eq:dualSVR}{{2.11}{19}{Support Vector Regression}{equation.2.11}{}}
\citation{boser1992training}
\citation{Platt1998}
\citation{keerthi2001improvements}
\citation{CC01a}
\citation{Boyd2004}
\citation{Schoelkopf2002}
\citation{bennett2000duality}
\citation{tsang2005core}
\citation{tsang2007simpler}
\citation{strack2013geometric}
\citation{zigic2016}
\citation{Kecman2014}
\citation{Huang2006}
\citation{Kecman2005}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.3}Methods for Solving the SVM Problem}{20}{section.2.3}}
\citation{herbrich2016learning}
\citation{kivinen2002large}
\citation{Schoelkopf2002}
\citation{Shalev2014}
\citation{shalev2011pegasos}
\citation{kivinen2004online}
\citation{bousquet2008tradeoffs}
\citation{Shalev2014}
\citation{collobert2004links}
\citation{kivinen2004online}
\citation{shalev2011pegasos}
\citation{kivinen2004online}
\citation{kecman2016fast}
\citation{herbrich2016learning}
\citation{kivinen2002large}
\citation{Schoelkopf2002}
\citation{Shalev2014}
\citation{shalev2011pegasos}
\citation{kecman2016ieee}
\citation{Melki2016}
\citation{melki2016fast}
\citation{collobert2004links}
\citation{kecman2016fast}
\citation{Spyromitros2014}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {3} Multi-Target SVR using Maximum Correlation Chains}{23}{chapter.3}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.1}Multi-Target Regression Background}{23}{section.3.1}}
\newlabel{sec:MTRbackground}{{3.1}{23}{Multi-Target Regression Background}{section.3.1}{}}
\citation{Spyromitros2014}
\citation{Tsoumakas2014}
\citation{Kocev2007}
\citation{Spyromitros2014}
\citation{Xioufis2016}
\citation{Spyromitros2014}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Notation}{24}{subsection.3.1.1}}
\newlabel{subsec:mtrnotation}{{3.1.1}{24}{Notation}{subsection.3.1.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Multi-Target Regression}{24}{subsection.3.1.2}}
\citation{Spyromitros2014}
\citation{mulan}
\citation{Spyromitros2014}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.2}Three Novel SVMs for Multi-Target Regression}{26}{section.3.2}}
\newlabel{sec:MTRproposal}{{3.2}{26}{Three Novel SVMs for Multi-Target Regression}{section.3.2}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces SVR Flow Diagram. Firstly, the SVR method divides the MT dataset into $m$ ST datasets, $\mathcal  {D}_1, \mathcal  {D}_2, \ldots  , \mathcal  {D}_m$. It then independently trains models, $h_1, h_2, \ldots  , h_m$, for each ST dataset.}}{26}{figure.3.1}}
\newlabel{diag:SVR}{{3.1}{26}{SVR Flow Diagram. Firstly, the SVR method divides the MT dataset into $m$ ST datasets, $\mathcal {D}_1, \mathcal {D}_2, \ldots , \mathcal {D}_m$. It then independently trains models, $h_1, h_2, \ldots , h_m$, for each ST dataset}{figure.3.1}{}}
\@writefile{loa}{\defcounter {refsection}{0}\relax }\@writefile{loa}{\contentsline {algorithm}{\numberline {3.1}{\ignorespaces MT Support Vector Regression (SVR)}}{26}{algorithm.3.1}}
\newlabel{alg:SVR}{{3.1}{26}{SVR Flow Diagram. Firstly, the SVR method divides the MT dataset into $m$ ST datasets, $\mathcal {D}_1, \mathcal {D}_2, \ldots , \mathcal {D}_m$. It then independently trains models, $h_1, h_2, \ldots , h_m$, for each ST dataset}{algorithm.3.1}{}}
\@writefile{loa}{\defcounter {refsection}{0}\relax }\@writefile{loa}{\contentsline {algorithm}{\numberline {3.2}{\ignorespaces Build Chained Model}}{27}{algorithm.3.2}}
\newlabel{alg:buildchainedmodel}{{3.2}{27}{Three Novel SVMs for Multi-Target Regression}{algorithm.3.2}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces SVRRC Flow Diagram on a dataset with 3 targets. SVRRC first builds the $6$ random chains of the target's indices ($3$ examples are shown). It then constructs a chained model by proceeding recursively over the chain, building a model, and appending the current target to the input space to predict the next target in the chain. }}{28}{figure.3.2}}
\newlabel{fig:svrrc}{{3.2}{28}{SVRRC Flow Diagram on a dataset with 3 targets. SVRRC first builds the $6$ random chains of the target's indices ($3$ examples are shown). It then constructs a chained model by proceeding recursively over the chain, building a model, and appending the current target to the input space to predict the next target in the chain}{figure.3.2}{}}
\@writefile{loa}{\defcounter {refsection}{0}\relax }\@writefile{loa}{\contentsline {algorithm}{\numberline {3.3}{\ignorespaces MT SVR with Random-Chains (SVRRC)}}{28}{algorithm.3.3}}
\newlabel{alg:SVRRC}{{3.3}{28}{SVRRC Flow Diagram on a dataset with 3 targets. SVRRC first builds the $6$ random chains of the target's indices ($3$ examples are shown). It then constructs a chained model by proceeding recursively over the chain, building a model, and appending the current target to the input space to predict the next target in the chain}{algorithm.3.3}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces SVRCC Flow Diagram on a sample dataset with 3 targets. SVRCC first finds the direction of maximum correlation among the targets and uses that order as the only chain. It then constructs the chained model as done in SVRRC. }}{29}{figure.3.3}}
\newlabel{fig:svrcc}{{3.3}{29}{SVRCC Flow Diagram on a sample dataset with 3 targets. SVRCC first finds the direction of maximum correlation among the targets and uses that order as the only chain. It then constructs the chained model as done in SVRRC}{figure.3.3}{}}
\@writefile{loa}{\defcounter {refsection}{0}\relax }\@writefile{loa}{\contentsline {algorithm}{\numberline {3.4}{\ignorespaces MT SVR with Max-Correlation Chain (SVRCC)}}{29}{algorithm.3.4}}
\newlabel{alg:SVRCC}{{3.4}{29}{SVRCC Flow Diagram on a sample dataset with 3 targets. SVRCC first finds the direction of maximum correlation among the targets and uses that order as the only chain. It then constructs the chained model as done in SVRRC}{algorithm.3.4}{}}
\citation{mulan}
\citation{Lichman:2013}
\citation{Spyromitros2014}
\citation{mulan}
\citation{Hall2009}
\citation{CC01a}
\newlabel{eq:corr}{{3.1}{30}{Three Novel SVMs for Multi-Target Regression}{equation.3.1}{}}
\newlabel{eq:corrcoef}{{3.2}{30}{Three Novel SVMs for Multi-Target Regression}{equation.3.2}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.3}Experimental Environment}{30}{section.3.3}}
\newlabel{sec:MTRexperiments}{{3.3}{30}{Experimental Environment}{section.3.3}{}}
\citation{Spyromitros2014}
\citation{Breiman1996}
\citation{Wu2015430}
\citation{Kocev2013}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Multi-Target (MT) Regression datasets}}{31}{table.3.1}}
\newlabel{tab:mtrdatasets}{{3.1}{31}{Multi-Target (MT) Regression datasets}{table.3.1}{}}
\newlabel{eq:hyperparammtr}{{3.3}{31}{Experimental Environment}{equation.3.3}{}}
\newlabel{eq:paramCmtr}{{3.3a}{31}{Experimental Environment}{equation.3.3a}{}}
\newlabel{eq:mtrparamG}{{3.3b}{31}{Experimental Environment}{equation.3.3b}{}}
\newlabel{eq:paramE}{{3.3c}{31}{Experimental Environment}{equation.3.3c}{}}
\citation{Dunn1961}
\citation{Wilcoxon1945}
\newlabel{eqn:aCC}{{3.4}{32}{Experimental Environment}{equation.3.4}{}}
\newlabel{eqn:MSE}{{3.5}{32}{Experimental Environment}{equation.3.5}{}}
\newlabel{eqn:armse}{{3.6}{32}{Experimental Environment}{equation.3.6}{}}
\newlabel{eqn:arrmse}{{3.7}{32}{Experimental Environment}{equation.3.7}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.4}Results \& Statistical Analysis}{33}{section.3.4}}
\newlabel{sec:MTRresults}{{3.4}{33}{Results \& Statistical Analysis}{section.3.4}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Average Correlation Coefficient}{33}{subsection.3.4.1}}
\newlabel{subsec:acc}{{3.4.1}{33}{Average Correlation Coefficient}{subsection.3.4.1}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3.2}{\ignorespaces Average Correlation Coefficient (aCC) for MT regressors}}{34}{table.3.2}}
\newlabel{tab:mtraccResults}{{3.2}{34}{Average Correlation Coefficient (aCC) for MT regressors}{table.3.2}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Bonferroni-Dunn test for aCC}}{34}{figure.3.4}}
\newlabel{fig:BonfDunnACC}{{3.4}{34}{Bonferroni-Dunn test for aCC}{figure.3.4}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3.3}{\ignorespaces Wilcoxon, Nemenyi, and Holm tests for aCC}}{34}{table.3.3}}
\newlabel{tab:statacc}{{3.3}{34}{Wilcoxon, Nemenyi, and Holm tests for aCC}{table.3.3}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3.4}{\ignorespaces Mean Square Error (MSE) for MT regressors}}{35}{table.3.4}}
\newlabel{tab:mseResults}{{3.4}{35}{Mean Square Error (MSE) for MT regressors}{table.3.4}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Bonferroni-Dunn test for MSE}}{35}{figure.3.5}}
\newlabel{fig:BonfDunnMSE}{{3.5}{35}{Bonferroni-Dunn test for MSE}{figure.3.5}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3.5}{\ignorespaces Wilcoxon, Nemenyi, and Holm tests for MSE}}{35}{table.3.5}}
\newlabel{tab:statmse}{{3.5}{35}{Wilcoxon, Nemenyi, and Holm tests for MSE}{table.3.5}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Mean Square Error}{36}{subsection.3.4.2}}
\newlabel{subsec:mse}{{3.4.2}{36}{Mean Square Error}{subsection.3.4.2}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.3}Average Root Mean Square Error}{36}{subsection.3.4.3}}
\newlabel{subsec:armse}{{3.4.3}{36}{Average Root Mean Square Error}{subsection.3.4.3}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3.6}{\ignorespaces Average Root Mean Square Error (aRMSE) for MT regressors}}{37}{table.3.6}}
\newlabel{tab:armseresults}{{3.6}{37}{Average Root Mean Square Error (aRMSE) for MT regressors}{table.3.6}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Bonferroni-Dunn test for aRMSE}}{37}{figure.3.6}}
\newlabel{fig:BonfDunnaRMSE}{{3.6}{37}{Bonferroni-Dunn test for aRMSE}{figure.3.6}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3.7}{\ignorespaces Wilcoxon, Nemenyi, and Holm tests for aRMSE}}{37}{table.3.7}}
\newlabel{tab:statarmse}{{3.7}{37}{Wilcoxon, Nemenyi, and Holm tests for aRMSE}{table.3.7}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.4}Average Relative Root Mean Square Error}{37}{subsection.3.4.4}}
\newlabel{subsec:arrmse}{{3.4.4}{37}{Average Relative Root Mean Square Error}{subsection.3.4.4}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3.8}{\ignorespaces Average Relative Root Mean Square Error (aRRMSE) for MT regressors}}{38}{table.3.8}}
\newlabel{tab:arrmseresults}{{3.8}{38}{Average Relative Root Mean Square Error (aRRMSE) for MT regressors}{table.3.8}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces Bonferroni-Dunn test for aRRMSE}}{38}{figure.3.7}}
\newlabel{fig:BonfDunnaRRMSE}{{3.7}{38}{Bonferroni-Dunn test for aRRMSE}{figure.3.7}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3.9}{\ignorespaces Wilcoxon, Nemenyi, and Holm tests for aRRMSE}}{38}{table.3.9}}
\newlabel{tab:statarrmse}{{3.9}{38}{Wilcoxon, Nemenyi, and Holm tests for aRRMSE}{table.3.9}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.5}Run Time}{39}{subsection.3.4.5}}
\newlabel{subsec:time}{{3.4.5}{39}{Run Time}{subsection.3.4.5}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.6}Discussion}{39}{subsection.3.4.6}}
\newlabel{sec:discussion}{{3.4.6}{39}{Discussion}{subsection.3.4.6}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3.10}{\ignorespaces Run Time (seconds) for MT regressors}}{40}{table.3.10}}
\newlabel{tab:timeresults}{{3.10}{40}{Run Time (seconds) for MT regressors}{table.3.10}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces Bonferroni-Dunn test for Run Time}}{40}{figure.3.8}}
\newlabel{fig:BonfDunnTime}{{3.8}{40}{Bonferroni-Dunn test for Run Time}{figure.3.8}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3.11}{\ignorespaces Wilcoxon, Nemenyi, and Holm tests for Run Time}}{40}{table.3.11}}
\newlabel{tab:stattime}{{3.11}{40}{Wilcoxon, Nemenyi, and Holm tests for Run Time}{table.3.11}{}}
\citation{melki2017multi}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.5}Conclusions}{41}{section.3.5}}
\newlabel{sec:MTRconclusions}{{3.5}{41}{Conclusions}{section.3.5}{}}
\citation{Amores2013}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {4} Multi-Instance SVM using Bag-Representatives }{43}{chapter.4}}
\newlabel{CHAP:MIRSVM}{{4}{43}{Multi-Instance SVM using Bag-Representatives}{chapter.4}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.1}Multi-Instance Classification Background}{43}{section.4.1}}
\newlabel{sec:mibackground}{{4.1}{43}{Multi-Instance Classification Background}{section.4.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Notation}{43}{subsection.4.1.1}}
\newlabel{subsec:minotation}{{4.1.1}{43}{Notation}{subsection.4.1.1}{}}
\citation{Dietterich1997}
\citation{Foulds2010}
\citation{Amores2013}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}Multi-Instance Classification}{44}{subsection.4.1.2}}
\newlabel{eqn:stas}{{4.1}{44}{Multi-Instance Classification}{equation.4.1}{}}
\newlabel{eqn:stasmax}{{4.2}{44}{Multi-Instance Classification}{equation.4.2}{}}
\citation{Dietterich1997}
\citation{Maron1998}
\citation{Zhang2001}
\citation{Auer2004}
\citation{Auer2004}
\citation{Carbonneau2016}
\citation{Chen2006}
\citation{Chen2004}
\citation{Fu2011}
\citation{Dong2006}
\citation{Wang2000}
\citation{Blockeel2005}
\citation{Bjerring2011}
\citation{Hall2009}
\citation{Frank2003}
\citation{Wang2014}
\citation{Doran201479}
\citation{Andrews2002}
\citation{Andrews2002}
\citation{Smola2002}
\citation{Blaschko2006}
\citation{Amores2013}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.2}Novel SVM for Multi-Instance Classification}{47}{section.4.2}}
\citation{Boyd2004}
\newlabel{eq:primalmirsvm}{{4.3}{48}{Novel SVM for Multi-Instance Classification}{equation.4.3}{}}
\newlabel{eq:primalmirsvm1}{{4.3a}{48}{Novel SVM for Multi-Instance Classification}{equation.4.3a}{}}
\newlabel{eqn:svmlagrangian}{{4.4}{48}{Novel SVM for Multi-Instance Classification}{equation.4.4}{}}
\newlabel{eqn:optcond1}{{4.5}{49}{Novel SVM for Multi-Instance Classification}{equation.4.5}{}}
\newlabel{eqn:optcond2}{{4.6}{49}{Novel SVM for Multi-Instance Classification}{equation.4.6}{}}
\newlabel{eqn:optcond3}{{4.7}{49}{Novel SVM for Multi-Instance Classification}{equation.4.7}{}}
\newlabel{eq:dualmirsvm1}{{4.8}{49}{Novel SVM for Multi-Instance Classification}{equation.4.8}{}}
\newlabel{eq:implicit1}{{4.8b}{49}{Novel SVM for Multi-Instance Classification}{equation.4.8b}{}}
\newlabel{eq:implicit2}{{4.8c}{49}{Novel SVM for Multi-Instance Classification}{equation.4.8c}{}}
\newlabel{eq:implicit3}{{4.8d}{49}{Novel SVM for Multi-Instance Classification}{equation.4.8d}{}}
\newlabel{eq:si}{{4.9}{49}{Novel SVM for Multi-Instance Classification}{equation.4.9}{}}
\citation{Huang2006}
\newlabel{eq:dualmirsvm}{{4.10}{50}{Novel SVM for Multi-Instance Classification}{equation.4.10}{}}
\newlabel{eq:gaussiankernel}{{4.11}{50}{Novel SVM for Multi-Instance Classification}{equation.4.11}{}}
\newlabel{eqn:bias}{{4.13}{50}{Novel SVM for Multi-Instance Classification}{equation.4.13}{}}
\newlabel{fig:mirsvm}{{4.2}{51}{Novel SVM for Multi-Instance Classification}{equation.4.13}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces  \relax \fontsize  {10.95}{13.6}\selectfont  \abovedisplayskip 11pt plus3pt minus6pt\belowdisplayskip \abovedisplayskip \abovedisplayshortskip \z@ plus3pt\belowdisplayshortskip 6.5pt plus3.5pt minus3pt \def \parsep 4.5pt plus 2pt minus 1pt \itemsep \parsep \topsep 9pt plus 3pt minus 5pt{\parsep 4.5pt plus 2pt minus 1pt \itemsep \parsep \topsep 9pt plus 3pt minus 5pt}A summary of the steps performed by MIRSVM. The representatives are first randomly initialized and continuously updated according to the current hyperplane, which is found using a quadratic programming solver. Upon completion, the model is returned along with the optimal bag-representatives.}}{51}{figure.4.1}}
\@writefile{loa}{\defcounter {refsection}{0}\relax }\@writefile{loa}{\contentsline {algorithm}{\numberline {4.1}{\ignorespaces Multi-Instance Representative SVM (MIRSVM)}}{51}{algorithm.4.1}}
\newlabel{alg:mirsvm}{{4.1}{51}{Novel SVM for Multi-Instance Classification}{algorithm.4.1}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Bag representative convergence plots on 9 datasets. The blue line shows the number of bag representatives that are equal from one iteration to the next. The red dashed line represents the total number of bags.}}{52}{figure.4.2}}
\newlabel{fig:convegence}{{4.2}{52}{Bag representative convergence plots on 9 datasets. The blue line shows the number of bag representatives that are equal from one iteration to the next. The red dashed line represents the total number of bags}{figure.4.2}{}}
\citation{Hall2009}
\citation{Alca2011}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Difference between MIRSVM and MISVM on a random $2$-dimensional toy dataset. Note the differing number of support vectors produced by the two methods. MIRSVM has $6$, one for each bag, and MISVM has $29$. Also note the smoother representation of the data distribution given by MIRSVM's decision boundary, unlike MISVM whose decision boundary was greatly influenced by the larger number of support vectors belonging to the negative class with respect to the only $2$ positive support vectors.}}{53}{figure.4.3}}
\newlabel{fig:diff}{{4.3}{53}{Difference between MIRSVM and MISVM on a random $2$-dimensional toy dataset. Note the differing number of support vectors produced by the two methods. MIRSVM has $6$, one for each bag, and MISVM has $29$. Also note the smoother representation of the data distribution given by MIRSVM's decision boundary, unlike MISVM whose decision boundary was greatly influenced by the larger number of support vectors belonging to the negative class with respect to the only $2$ positive support vectors}{figure.4.3}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.3}Experimental Environment}{53}{section.4.3}}
\citation{Xu2003}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Multi-Instance (MI) Classification datasets}}{54}{table.4.1}}
\newlabel{tab:Dataset}{{4.1}{54}{Multi-Instance (MI) Classification datasets}{table.4.1}{}}
\newlabel{eq:hyperparam}{{4.14}{55}{Experimental Environment}{equation.4.14}{}}
\newlabel{eq:paramC}{{4.14a}{55}{Experimental Environment}{equation.4.14a}{}}
\newlabel{eq:miparamG}{{4.14b}{55}{Experimental Environment}{equation.4.14b}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.4}Results \& Statistical Analysis}{55}{section.4.4}}
\newlabel{eq:metrics}{{4.15}{56}{Results \& Statistical Analysis}{equation.4.15}{}}
\newlabel{eq:accuracy}{{4.15a}{56}{Results \& Statistical Analysis}{equation.4.15a}{}}
\newlabel{eq:precision}{{4.15b}{56}{Results \& Statistical Analysis}{equation.4.15b}{}}
\newlabel{eq:recall}{{4.15c}{56}{Results \& Statistical Analysis}{equation.4.15c}{}}
\newlabel{eq:kappa}{{4.15d}{56}{Results \& Statistical Analysis}{equation.4.15d}{}}
\newlabel{eq:auc}{{4.15e}{56}{Results \& Statistical Analysis}{equation.4.15e}{}}
\citation{Dunn1961}
\citation{Holander1999}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}Accuracy}{57}{subsection.4.4.1}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces Accuracy for MI classifiers}}{58}{table.4.2}}
\newlabel{tab:accResults}{{4.2}{58}{Accuracy for MI classifiers}{table.4.2}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Bonferroni-Dunn test for Accuracy}}{58}{figure.4.4}}
\newlabel{fig:BonfDunnacc}{{4.4}{58}{Bonferroni-Dunn test for Accuracy}{figure.4.4}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.3}{\ignorespaces Holm and Wilcoxon tests for Accuracy}}{58}{table.4.3}}
\newlabel{tab:MIstatacc}{{4.3}{58}{Holm and Wilcoxon tests for Accuracy}{table.4.3}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.2}Precision \& Recall}{59}{subsection.4.4.2}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.4}{\ignorespaces Precision for MI classifiers}}{59}{table.4.4}}
\newlabel{tab:preResults}{{4.4}{59}{Precision for MI classifiers}{table.4.4}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Bonferroni-Dunn test for Precision}}{59}{figure.4.5}}
\newlabel{fig:BonfDunnprec}{{4.5}{59}{Bonferroni-Dunn test for Precision}{figure.4.5}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.5}{\ignorespaces Holm and Wilcoxon tests for Precision}}{59}{table.4.5}}
\newlabel{tab:statprec}{{4.5}{59}{Holm and Wilcoxon tests for Precision}{table.4.5}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.6}{\ignorespaces Recall for MI classifiers}}{60}{table.4.6}}
\newlabel{tab:recResults}{{4.6}{60}{Recall for MI classifiers}{table.4.6}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Bonferroni-Dunn test for Recall}}{60}{figure.4.6}}
\newlabel{fig:BonfDunnrec}{{4.6}{60}{Bonferroni-Dunn test for Recall}{figure.4.6}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.7}{\ignorespaces Holm and Wilcoxon tests for Recall}}{60}{table.4.7}}
\newlabel{tab:statrec}{{4.7}{60}{Holm and Wilcoxon tests for Recall}{table.4.7}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.8}{\ignorespaces Cohen's Kappa Rate for MI classifiers}}{61}{table.4.8}}
\newlabel{tab:kappaResults}{{4.8}{61}{Cohen's Kappa Rate for MI classifiers}{table.4.8}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces Bonferroni-Dunn test for Cohen's Kappa rate}}{61}{figure.4.7}}
\newlabel{fig:BonfDunnkappa}{{4.7}{61}{Bonferroni-Dunn test for Cohen's Kappa rate}{figure.4.7}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.9}{\ignorespaces Holm and Wilcoxon tests for Cohen's Kappa rate}}{61}{table.4.9}}
\newlabel{tab:statkappa}{{4.9}{61}{Holm and Wilcoxon tests for Cohen's Kappa rate}{table.4.9}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.3}Cohen's Kappa Rate}{61}{subsection.4.4.3}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.4}Area Under ROC Curve}{62}{subsection.4.4.4}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.10}{\ignorespaces AUC for MI classifiers}}{62}{table.4.10}}
\newlabel{tab:aucResults}{{4.10}{62}{AUC for MI classifiers}{table.4.10}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces Bonferroni-Dunn test for AUC}}{62}{figure.4.8}}
\newlabel{fig:BonfDunnauc}{{4.8}{62}{Bonferroni-Dunn test for AUC}{figure.4.8}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.11}{\ignorespaces Holm and Wilcoxon tests for AUC}}{62}{table.4.11}}
\newlabel{tab:statauc}{{4.11}{62}{Holm and Wilcoxon tests for AUC}{table.4.11}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.5}Overall Comparison}{63}{subsection.4.4.5}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.12}{\ignorespaces Run Time (seconds) for MI classifiers}}{64}{table.4.12}}
\newlabel{tab:time}{{4.12}{64}{Run Time (seconds) for MI classifiers}{table.4.12}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.13}{\ignorespaces Overall ranks comparison for MI classifiers}}{64}{table.4.13}}
\newlabel{tab:metarank}{{4.13}{64}{Overall ranks comparison for MI classifiers}{table.4.13}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces Bonferroni-Dunn test for overall ranks comparison}}{64}{figure.4.9}}
\newlabel{fig:BonfDunnpmeta}{{4.9}{64}{Bonferroni-Dunn test for overall ranks comparison}{figure.4.9}{}}
\citation{melki2018mirsvm}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.5}Conclusions}{65}{section.4.5}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {5} Novel OnLine SVM using Worst-Violators}{67}{chapter.5}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {5.1}Online Learning Background}{67}{section.5.1}}
\citation{kecman2016fast}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Notation}{68}{subsection.5.1.1}}
\newlabel{subsec:notation}{{5.1.1}{68}{Notation}{subsection.5.1.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {5.2}Novel Online Learning Algorithm using Worst-Violators}{68}{section.5.2}}
\newlabel{eq:wv}{{5.1}{69}{Novel Online Learning Algorithm using Worst-Violators}{equation.5.1}{}}
\newlabel{eq:l1svm}{{5.2}{69}{Novel Online Learning Algorithm using Worst-Violators}{equation.5.2}{}}
\citation{Kecman2001}
\citation{Shalev2014}
\newlabel{eq:subgrful}{{5.3}{70}{Novel Online Learning Algorithm using Worst-Violators}{equation.5.3}{}}
\newlabel{eq:alphaupdate}{{5.4}{71}{Novel Online Learning Algorithm using Worst-Violators}{equation.5.4}{}}
\newlabel{eq:upbias}{{5.5}{71}{Novel Online Learning Algorithm using Worst-Violators}{equation.5.5}{}}
\newlabel{eq:upoutput}{{5.6}{71}{Novel Online Learning Algorithm using Worst-Violators}{equation.5.6}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces A case of classifying 2-dimensional normally distributed data with different covariance matrices, (left) for 200 and (right) 2000 data points. The theoretical separation boundary (denoted as the Bayes Separation Boundary) is quadratic and is shown as the dashed black curve. The other two separation boundaries shown are the ones obtained by OLLAWV and SMO (implemented within LIBSVM), respectively. In this particular case (left), the difference between the OLLAWV boundary and the SMO boundary is hardly visible. The case presented on the right shows that, with an increase of training samples, the OLLAWV and SMO boundaries converge to the theoretical Bayesian solution.}}{72}{figure.5.1}}
\newlabel{fig:ollawvseparation}{{5.1}{72}{A case of classifying 2-dimensional normally distributed data with different covariance matrices, (left) for 200 and (right) 2000 data points. The theoretical separation boundary (denoted as the Bayes Separation Boundary) is quadratic and is shown as the dashed black curve. The other two separation boundaries shown are the ones obtained by OLLAWV and SMO (implemented within LIBSVM), respectively. In this particular case (left), the difference between the OLLAWV boundary and the SMO boundary is hardly visible. The case presented on the right shows that, with an increase of training samples, the OLLAWV and SMO boundaries converge to the theoretical Bayesian solution}{figure.5.1}{}}
\citation{Derrac2011}
\citation{Lichman:2013}
\citation{tsang2005core}
\citation{CC01a}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {5.3}Experimental Environment}{73}{section.5.3}}
\@writefile{loa}{\defcounter {refsection}{0}\relax }\@writefile{loa}{\contentsline {algorithm}{\numberline {5.1}{\ignorespaces OnLine Learning Algorithm using Worst-Violators (OLLAWV)}}{74}{algorithm.5.1}}
\newlabel{alg:ollawv}{{5.1}{74}{Novel Online Learning Algorithm using Worst-Violators}{algorithm.5.1}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces A summary of the steps performed by OLLAWV. The model parameters ($\bm  {\alpha }$, $b$, $\bm  {S}$) and the algorithm variables ($\bm  {o}$, $t$, $wv$, and $yo$) are first initialized. The worst-violator with respect to the current hyperplane is then found and the model parameters are then updated. Once no more violating samples are found, the model is returned.}}{74}{figure.5.2}}
\newlabel{fig:ollawv}{{5.2}{74}{A summary of the steps performed by OLLAWV. The model parameters ($\bm \alpha $, $b$, $\bm S$) and the algorithm variables ($\bm o$, $t$, $wv$, and $yo$) are first initialized. The worst-violator with respect to the current hyperplane is then found and the model parameters are then updated. Once no more violating samples are found, the model is returned}{figure.5.2}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces Datasets}}{75}{table.5.1}}
\newlabel{tab:Dataset}{{5.1}{75}{Datasets}{table.5.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {5.4}Results \& Statistical Analysis}{75}{section.5.4}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {5.5}Conclusions}{75}{section.5.5}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {6} Conclusions}{76}{chapter.6}}
\citation{bottou2010large}
\citation{kivinen2004online}
\citation{shalev2011pegasos}
\citation{zhang2004solving}
\citation{panagiotakopoulos2013stochastic}
\citation{cauwenberghs2001incremental}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {7} Future Work}{77}{chapter.7}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{References}{79}{chapter*.11}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{Vita}{88}{chapter*.12}}
